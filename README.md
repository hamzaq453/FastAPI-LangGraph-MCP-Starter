# FastAPI + LangGraph + MCP Starter Template

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.2+-orange.svg)](https://langchain-ai.github.io/langgraph/)
[![MCP](https://img.shields.io/badge/MCP-FastMCP_2.0-purple.svg)](https://github.com/jlowin/fastmcp)

Production-ready starter template for building AI agents with **FastAPI** (API layer), **LangGraph** (agent orchestration), and **MCP** (Model Context Protocol for tools).

## ğŸš€ Features

- **FastAPI Backend**: High-performance async API with automatic OpenAPI docs
- **LangGraph Agent**: Stateful ReAct-pattern agent with tool calling
- **MCP Tools**: Standardized tool protocol with TODO, calculator, and weather
- **OpenRouter Integration**: Easy LLM provider switching (GPT-4o default)
- **Streaming Responses**: Real-time SSE streaming of agent thoughts and actions
- **LangSmith Observability**: Optional tracing and debugging (Phase II)
- **Structured Logging**: JSON logs for production monitoring
- **Docker Ready**: One-command setup with Docker Compose
- **Fully Tested**: Comprehensive unit tests with pytest
- **Type Safe**: Full type hints with Pydantic validation

## ğŸ“‹ What's Included

### API Endpoints
- `GET /health` - Health check
- `POST /chat` - Chat with AI agent
- `GET /chat/stream` - Stream agent responses via SSE (Phase II)

### MCP Tools
- **TODO Management**: Add, list, complete, delete tasks
- **Calculator**: Safe mathematical expression evaluation
- **Weather**: Get current weather for any city (Phase II)

### Agent Capabilities
The LangGraph agent can:
- Manage your TODO list via natural language
- Perform calculations
- Get weather information for cities worldwide
- Combine multiple tools to complete complex tasks

## ğŸƒ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose (optional but recommended)

### 1. Clone and Setup

```bash
git clone https://github.com/yourusername/fastapi-langgraph-mcp-starter
cd fastapi-langgraph-mcp-starter
cp .env.example .env
```

### 2. Configure Environment

Edit `.env` and add your OpenRouter API key:

```env
OPENROUTER_API_KEY=your_api_key_here
```

Get your API key from [OpenRouter](https://openrouter.ai/).

### 3. Run with Docker (Recommended)

```bash
docker-compose up
```

The API will be available at `http://localhost:8000`.

### 4. Run Locally (Alternative)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e .

# Run the application
python -m app.main
```

## ğŸ§ª Testing

### Health Check

```bash
curl http://localhost:8000/health
```

### Chat with Agent

**Add a TODO:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Add a todo: Buy groceries"}'
```

**List TODOs:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Show me all my todos"}'
```

**Calculate:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Calculate 25 * 4 + 10"}'
```

**Complex Task:**
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Add 3 todos: buy milk, call mom, finish report. Then calculate 100 / 5"}'
```

## ğŸ§ª Run Tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html
```

## ğŸ“š API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ—ï¸ Project Structure

```
fastapi-langgraph-mcp-starter/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py        # API endpoints
â”‚   â”‚   â””â”€â”€ schemas.py       # Request/Response models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ llm_factory.py   # LLM provider abstraction
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ state.py         # Agent state schema
â”‚   â”‚   â”œâ”€â”€ nodes.py         # Graph node functions
â”‚   â”‚   â””â”€â”€ graph.py         # LangGraph workflow
â”‚   â””â”€â”€ mcp/
â”‚       â”œâ”€â”€ server.py        # MCP server
â”‚       â””â”€â”€ tools/
â”‚           â”œâ”€â”€ todo.py      # TODO tool
â”‚           â””â”€â”€ calculator.py # Calculator tool
â”œâ”€â”€ tests/                   # Unit tests
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ docker-compose.yml       # Docker Compose setup
â””â”€â”€ pyproject.toml           # Dependencies
```

## ğŸ”§ Configuration

All configuration is managed via environment variables in `.env`:

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENROUTER_API_KEY` | OpenRouter API key | Required |
| `MODEL_NAME` | LLM model identifier | `openai/gpt-4o` |
| `MODEL_TEMPERATURE` | Sampling temperature | `0.7` |
| `MODEL_MAX_TOKENS` | Max response tokens | `2000` |
| `API_PORT` | API server port | `8000` |
| `CORS_ORIGINS` | Allowed CORS origins | `http://localhost:3000,http://localhost:8000` |
| `WEATHER_API_KEY` | OpenWeatherMap API key (optional) | `` |
| `LANGSMITH_API_KEY` | LangSmith API key (optional) | `` |
| `LANGSMITH_ENABLED` | Enable LangSmith tracing | `false` |
| `LOG_LEVEL` | Logging level | `INFO` |
| `JSON_LOGS` | Use JSON log format | `false` |

## ğŸ¯ Customization

### Add a New Tool

1. Create tool function in `app/mcp/tools/`:

```python
# app/mcp/tools/weather.py
def get_weather(city: str) -> dict:
    """Get weather for a city."""
    # Your implementation
    return {"city": city, "temp": 72}
```

2. Register in MCP server (`app/mcp/server.py`):

```python
from app.mcp.tools import weather

@mcp.tool()
def get_weather(city: str) -> dict:
    """Get current weather for a city."""
    return weather.get_weather(city)
```

3. Add to agent tools (`app/agent/nodes.py`):

```python
@tool
def get_weather_tool(city: str) -> dict:
    """Get current weather for a city."""
    return weather.get_weather(city)

# Add to tools list
tools = [..., get_weather_tool]
```

### Change LLM Provider

Edit `.env`:

```env
MODEL_NAME=anthropic/claude-3.5-sonnet
```

OpenRouter supports 100+ models. See [OpenRouter Models](https://openrouter.ai/models).

## ğŸ—ºï¸ Roadmap

### Phase I âœ…
- Core FastAPI + LangGraph + MCP integration
- TODO and calculator tools
- Docker setup
- Unit tests

### Phase II (Current) âœ…
- Streaming responses (SSE)
- Weather tool integration
- LangSmith observability
- Structured logging

### Phase III (Planned)
- PostgreSQL persistence
- Conversation memory
- OAuth 2.0 authentication
- Multi-MCP server support
- Rate limiting

### Phase IV (Future)
- Multi-agent workflows
- RAG integration
- Web UI
- Advanced monitoring

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [LangGraph](https://langchain-ai.github.io/langgraph/) - Agent orchestration
- [FastMCP](https://github.com/jlowin/fastmcp) - Model Context Protocol
- [OpenRouter](https://openrouter.ai/) - Unified LLM API

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/fastapi-langgraph-mcp-starter/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/fastapi-langgraph-mcp-starter/discussions)

---

**Star â­ this repo if you find it useful!**
"# LangGrapgh-MCP-" 
